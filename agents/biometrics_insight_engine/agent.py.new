"""
Agente especializado en análisis e interpretación de datos biométricos.

Este agente procesa datos biométricos como HRV, sueño, glucosa, 
composición corporal, etc., para proporcionar insights personalizados
y recomendaciones basadas en patrones individuales.

Implementa los protocolos oficiales A2A y ADK para comunicación entre agentes.
"""
import logging
import uuid
import time
import json
from typing import Dict, Any, Optional, List, Union

try:
    from google.adk.toolkit import Toolkit
except ImportError:
    from adk.toolkit import Toolkit

from clients.gemini_client import GeminiClient
from clients.supabase_client import SupabaseClient
from tools.mcp_toolkit import MCPToolkit
from tools.vertex_gemini_tools import VertexGeminiGenerateSkill
from agents.base.adk_agent import ADKAgent
from core.agent_card import AgentCard, Example
from core.state_manager import StateManager
from core.logging_config import get_logger
from core.contracts import create_task, create_result, validate_task, validate_result

# Configurar logger
logger = get_logger(__name__)


class BiometricsInsightEngine(ADKAgent):
    """
    Agente especializado en análisis e interpretación de datos biométricos.
    
    Este agente procesa datos biométricos como HRV, sueño, glucosa, 
    composición corporal, etc., para proporcionar insights personalizados
    y recomendaciones basadas en patrones individuales.
    
    Implementa los protocolos oficiales A2A y ADK para comunicación entre agentes.
    """
    
    def __init__(self, toolkit: Optional[Toolkit] = None, a2a_server_url: Optional[str] = None, state_manager: Optional[StateManager] = None):
        # Definir capacidades y habilidades
        capabilities = [
            "biometric_analysis",
            "pattern_recognition",
            "trend_identification",
            "personalized_insights",
            "data_visualization",
            "image_analysis",
            "multimodal_processing"
        ]
        
        # Definir skills siguiendo el formato A2A con mejores prácticas
        skills = [
            {
                "id": "biometrics-insight-biometric-analysis",
                "name": "Análisis de Datos Biométricos",
                "description": "Analiza e interpreta datos biométricos como HRV, sueño, glucosa, composición corporal y otros marcadores para identificar patrones y oportunidades de mejora",
                "tags": ["biometrics", "health-data", "analysis", "hrv", "sleep", "glucose"],
                "examples": [
                    "Analiza mis datos de HRV de la última semana",
                    "Interpreta mis métricas de sueño y explica qué significan",
                    "Qué indican mis niveles de glucosa después de las comidas"
                ],
                "inputModes": ["text", "json"],
                "outputModes": ["text", "json", "markdown"]
            },
            {
                "id": "biometrics-insight-pattern-recognition",
                "name": "Reconocimiento de Patrones",
                "description": "Identifica patrones recurrentes en datos biométricos a lo largo del tiempo y su relación con hábitos, comportamientos y factores externos",
                "tags": ["patterns", "correlations", "time-series", "trends", "causality"],
                "examples": [
                    "¿Qué patrones ves en mi recuperación relacionados con mi alimentación?",
                    "Identifica patrones en mi HRV relacionados con mi calidad de sueño",
                    "¿Cómo afectan mis entrenamientos a mis métricas de recuperación?"
                ],
                "inputModes": ["text", "json"],
                "outputModes": ["text", "json", "markdown"]
            },
            {
                "id": "biometrics-insight-trend-identification",
                "name": "Identificación de Tendencias",
                "description": "Analiza tendencias a largo plazo en datos biométricos para identificar mejoras, deterioros o cambios significativos en el tiempo",
                "tags": ["trends", "longitudinal-analysis", "progress", "regression", "changes"],
                "examples": [
                    "Muestra la evolución de mi HRV durante los últimos 3 meses",
                    "¿Cómo ha cambiado mi calidad de sueño desde que empecé a meditar?",
                    "Analiza la tendencia de mi recuperación después de entrenamientos intensos"
                ],
                "inputModes": ["text", "json"],
                "outputModes": ["text", "json", "markdown"]
            },
            {
                "id": "biometrics-insight-data-visualization",
                "name": "Visualización de Datos",
                "description": "Crea representaciones visuales de datos biométricos para facilitar la comprensión de patrones y relaciones entre diferentes métricas",
                "tags": ["visualization", "charts", "graphs", "comparison", "dashboard"],
                "examples": [
                    "Muestra la relación entre mi sueño y mi HRV",
                    "Visualiza mis niveles de estrés durante la semana laboral vs. fin de semana",
                    "Compara mis métricas de recuperación antes y después de cambiar mi dieta"
                ],
                "inputModes": ["text", "json"],
                "outputModes": ["text", "json", "markdown", "image"]
            },
            {
                "id": "biometrics-insight-image-analysis",
                "name": "Análisis de Imágenes Biométricas",
                "description": "Analiza imágenes de composición corporal, resultados de pruebas médicas y otras visualizaciones biométricas para extraer información relevante",
                "tags": ["image-analysis", "body-composition", "medical-tests", "visual-data"],
                "examples": [
                    "Analiza esta imagen de mi composición corporal",
                    "Interpreta los resultados de mi DEXA scan",
                    "¿Qué indican estos resultados de mi análisis de sangre?"
                ],
                "inputModes": ["text", "image", "multimodal"],
                "outputModes": ["text", "json", "markdown"]
            },
            {
                "id": "biometrics-insight-multimodal-analysis",
                "name": "Análisis Multimodal de Datos Biométricos",
                "description": "Procesa y analiza conjuntamente texto e imágenes relacionados con datos biométricos para proporcionar insights más completos",
                "tags": ["multimodal", "combined-analysis", "text-and-image", "comprehensive-insights"],
                "examples": [
                    "Compara estas dos imágenes de mi composición corporal y explica los cambios",
                    "Analiza esta captura de pantalla de mi app de HRV y explica qué significan estos valores",
                    "Interpreta estos resultados de laboratorio y sugiere mejoras basadas en mis objetivos"
                ],
                "inputModes": ["text", "image", "multimodal"],
                "outputModes": ["text", "json", "markdown"]
            }
        ]
        
        # Inicializar agente base con los parámetros definidos
        super().__init__(
            agent_id="biometrics_insight_engine",
            name="NGX Biometrics Insight Engine",
            description="Especialista en análisis e interpretación de datos biométricos para proporcionar insights personalizados y recomendaciones basadas en patrones individuales.",
            capabilities=capabilities,
            toolkit=toolkit,
            a2a_server_url=a2a_server_url or "https://biometrics-api.ngx-agents.com/a2a",
            state_manager=state_manager,
            version="1.2.0",
            skills=skills,
            provider={
                "organization": "NGX Health & Performance",
                "url": "https://ngx-agents.com"
            },
            documentation_url="https://docs.ngx-agents.com/biometrics-insight-engine"
        )
        
        # Inicializar clientes y herramientas
        self.gemini_client = GeminiClient()
        self.supabase_client = SupabaseClient()
        
        # Inicializar procesadores de visión y multimodales
        try:
            from core.vision_processor import VisionProcessor
            from infrastructure.adapters.multimodal_adapter import MultimodalAdapter
            from clients.vertex_ai.vision_client import VertexAIVisionClient
            from clients.vertex_ai.multimodal_client import VertexAIMultimodalClient
            
            # Inicializar procesador de visión
            self.vision_processor = VisionProcessor()
            logger.info("Procesador de visión inicializado correctamente")
            
            # Inicializar adaptador multimodal
            self.multimodal_adapter = MultimodalAdapter()
            logger.info("Adaptador multimodal inicializado correctamente")
            
            # Inicializar clientes especializados
            self.vision_client = VertexAIVisionClient()
            self.multimodal_client = VertexAIMultimodalClient()
            logger.info("Clientes de visión y multimodal inicializados correctamente")
            
            # Inicializar tracer para telemetría
            from opentelemetry import trace
            self.tracer = trace.get_tracer(__name__)
            logger.info("Tracer para telemetría inicializado correctamente")
            
            # Marcar capacidades como disponibles
            self._vision_capabilities_available = True
        except ImportError as e:
            logger.warning(f"No se pudieron inicializar algunos componentes para capacidades avanzadas: {e}")
            # Crear implementaciones simuladas para mantener la compatibilidad
            self._vision_capabilities_available = False
        
        # Inicializar estado interno
        self._state = {}
    
    async def _get_context(self, user_id: Optional[str], session_id: Optional[str]) -> Dict[str, Any]:
        """
        Obtiene el contexto de la conversación desde el StateManager.
        
        Args:
            user_id: ID del usuario
            session_id: ID de la sesión
            
        Returns:
            Dict[str, Any]: Contexto de la conversación
        """
        context = {
            "history": [],
            "analyses": [],
            "user_profile": {},
            "biometric_data": {}
        }
        
        if user_id and session_id and self.state_manager:
            try:
                # Intentar obtener el contexto del StateManager
                stored_context = await self.state_manager.get_context(user_id, session_id)
                if stored_context:
                    context = stored_context
                    logger.info(f"Contexto recuperado para user_id={user_id}, session_id={session_id}")
            except Exception as e:
                logger.warning(f"Error al obtener contexto desde StateManager: {e}")
        
        return context
    
    async def _update_context(self, context: Dict[str, Any], user_id: Optional[str], session_id: Optional[str]) -> None:
        """
        Actualiza el contexto de la conversación en el StateManager.
        
        Args:
            context: Contexto actualizado
            user_id: ID del usuario
            session_id: ID de la sesión
        """
        if user_id and session_id and self.state_manager:
            try:
                await self.state_manager.set_context(user_id, session_id, context)
                logger.info(f"Contexto actualizado para user_id={user_id}, session_id={session_id}")
            except Exception as e:
                logger.warning(f"Error al guardar contexto en StateManager: {e}")
    
    async def _run_async_impl(self, input_text: str, user_id: Optional[str] = None, 
                       session_id: Optional[str] = None, **kwargs) -> Dict[str, Any]:
        """
        Implementación asíncrona del procesamiento del agente BiometricsInsightEngine.
        
        Sobrescribe el método de la clase base para proporcionar la implementación
        específica del agente especializado en análisis de datos biométricos.
        
        Args:
            input_text: Texto de entrada del usuario
            user_id: ID del usuario (opcional)
            session_id: ID de la sesión (opcional)
            **kwargs: Argumentos adicionales
            
        Returns:
            Dict[str, Any]: Respuesta estandarizada del agente
        """
        # Delegamos al método _process_request para el procesamiento principal
        return await self._process_request(input_text, user_id, session_id, **kwargs)
    
    async def _process_request(self, input_text: str, user_id: Optional[str] = None, 
                           session_id: Optional[str] = None, **kwargs) -> Dict[str, Any]:
        """
        Procesa la solicitud del usuario y genera una respuesta utilizando las skills adecuadas.
        
        Args:
            input_text: Texto de entrada del usuario
            user_id: ID del usuario (opcional)
            session_id: ID de la sesión (opcional)
            **kwargs: Argumentos adicionales
            
        Returns:
            Dict[str, Any]: Respuesta estandarizada del agente
        """
        start_time = time.time()
        result = {}
        analysis_id = None
        response_text = ""
        response_type = "text"
        
        try:
            # Generar ID de usuario y sesión si no se proporcionan
            user_id = user_id or str(uuid.uuid4())
            session_id = session_id or str(uuid.uuid4())
            
            # Obtener contexto de la conversación
            context = await self._get_context(user_id, session_id)
            
            # Obtener perfil del usuario si está disponible
            user_profile = kwargs.get("user_profile", {})
            
            # Obtener datos biométricos del usuario
            # En un entorno real, esto se obtendría de una API o base de datos
            # Para este ejemplo, usamos datos de muestra
            biometric_data = kwargs.get("biometric_data", self._get_sample_biometric_data())
            
            # Verificar si hay imágenes en la entrada
            image_data = kwargs.get("image_data")
            has_image = image_data is not None
            
            # Analizar la entrada del usuario para determinar la skill a utilizar
            if has_image and any(keyword in input_text.lower() for keyword in ["analiza", "interpreta", "examina", "evalúa"]):
                # Usar skill de análisis de imágenes
                if self._vision_capabilities_available:
                    try:
                        result = await self.execute_skill("image_analysis",
                                                       input_text=input_text,
                                                       image_data=image_data,
                                                       biometric_data=biometric_data,
                                                       user_profile=user_profile,
                                                       context=context)
                        
                        # Generar respuesta
                        if isinstance(result, dict) and "response" in result:
                            response_text = result["response"]
                        else:
                            # Convertir resultado estructurado a texto
                            response_text = "Análisis de imagen biométrica:\n\n"
                            if isinstance(result, dict):
                                for key, value in result.items():
                                    if key != "response":
                                        response_text += f"**{key.replace('_', ' ').title()}**: {value}\n"
                            else:
                                response_text = str(result)
                        
                        # Almacenar resultado en el estado
                        image_analyses = self._state.get("image_analyses", {})
                        analysis_id = str(uuid.uuid4())
                        image_analyses[analysis_id] = result
                        self.update_state("image_analyses", image_analyses)
                        response_type = "image_analysis"
                        
                    except Exception as e:
                        logger.error(f"Error al ejecutar skill image_analysis: {e}")
                        response_text = "Lo siento, ha ocurrido un error al analizar la imagen biométrica."
                        result = {"error": str(e)}
                        analysis_id = None
                else:
                    response_text = "Lo siento, las capacidades de análisis de imágenes no están disponibles en este momento."
                    result = {"error": "Capacidades de visión no disponibles"}
                    analysis_id = None
                    response_type = "error"
            
            elif has_image and any(keyword in input_text.lower() for keyword in ["compara", "diferencia", "cambio", "progreso", "antes y después"]):
                # Usar skill de análisis multimodal para comparación
                if self._vision_capabilities_available:
                    try:
                        result = await self.execute_skill("multimodal_analysis",
                                                       input_text=input_text,
                                                       image_data=image_data,
                                                       biometric_data=biometric_data,
                                                       user_profile=user_profile,
                                                       context=context)
                        
                        # Generar respuesta
                        if isinstance(result, dict) and "response" in result:
                            response_text = result["response"]
                        else:
                            # Convertir resultado estructurado a texto
                            response_text = "Análisis multimodal de datos biométricos:\n\n"
                            if isinstance(result, dict):
                                for key, value in result.items():
                                    if key != "response":
                                        response_text += f"**{key.replace('_', ' ').title()}**: {value}\n"
                            else:
                                response_text = str(result)
                        
                        # Almacenar resultado en el estado
                        multimodal_analyses = self._state.get("multimodal_analyses", {})
                        analysis_id = str(uuid.uuid4())
                        multimodal_analyses[analysis_id] = result
                        self.update_state("multimodal_analyses", multimodal_analyses)
                        response_type = "multimodal_analysis"
                        
                    except Exception as e:
                        logger.error(f"Error al ejecutar skill multimodal_analysis: {e}")
                        response_text = "Lo siento, ha ocurrido un error al realizar el análisis multimodal."
                        result = {"error": str(e)}
                        analysis_id = None
                else:
                    response_text = "Lo siento, las capacidades de análisis multimodal no están disponibles en este momento."
                    result = {"error": "Capacidades multimodales no disponibles"}
                    analysis_id = None
                    response_type = "error"
            
            elif any(keyword in input_text.lower() for keyword in ["visualiza", "gráfico", "muestra", "compara", "dashboard"]):
                # Usar skill de visualización de datos
                try:
                    result = await self.execute_skill("data_visualization", 
                                                   input_text=input_text, 
                                                   biometric_data=biometric_data,
                                                   user_profile=user_profile, 
                                                   context=context)
                    
                    # Generar respuesta
                    if isinstance(result, dict) and "response" in result:
                        response_text = result["response"]
                    else:
                        # Convertir resultado estructurado a texto
                        response_text = "Visualización de datos biométricos:\n\n"
                        if isinstance(result, dict):
                            for key, value in result.items():
                                if key != "response":
                                    response_text += f"**{key.replace('_', ' ').title()}**: {value}\n"
                        else:
                            response_text = str(result)
                    
                    # Almacenar resultado en el estado
                    visualizations = self._state.get("visualizations", {})
                    analysis_id = str(uuid.uuid4())
                    visualizations[analysis_id] = result
                    self.update_state("visualizations", visualizations)
                    response_type = "data_visualization"
                    
                except Exception as e:
                    logger.error(f"Error al ejecutar skill data_visualization: {e}")
                    response_text = "Lo siento, ha ocurrido un error al visualizar tus datos biométricos."
                    result = {"error": str(e)}
                    analysis_id = None
                
            elif any(keyword in input_text.lower() for keyword in ["tendencia", "tendencias", "evolución", "cambio", "progreso"]):
                # Usar skill de análisis de tendencias
                try:
                    result = await self.execute_skill("trend_identification", 
                                                   input_text=input_text, 
                                                   biometric_data=biometric_data,
                                                   user_profile=user_profile, 
                                                   context=context)
                    
                    # Generar respuesta
                    if isinstance(result, dict) and "response" in result:
                        response_text = result["response"]
                    else:
                        # Convertir resultado estructurado a texto
                        response_text = "Análisis de tendencias biométricas:\n\n"
                        if isinstance(result, dict):
                            for key, value in result.items():
                                if key != "response":
                                    response_text += f"**{key.replace('_', ' ').title()}**: {value}\n"
                        else:
                            response_text = str(result)
                    
                    # Almacenar resultado en el estado
                    trend_analyses = self._state.get("trend_analyses", {})
                    analysis_id = str(uuid.uuid4())
                    trend_analyses[analysis_id] = result
                    self.update_state("trend_analyses", trend_analyses)
                    response_type = "trend_analysis"
                    
                except Exception as e:
                    logger.error(f"Error al ejecutar skill trend_identification: {e}")
                    response_text = "Lo siento, ha ocurrido un error al analizar las tendencias de tus datos biométricos."
                    result = {"error": str(e)}
                    analysis_id = None
                
            elif any(keyword in input_text.lower() for keyword in ["patrón", "patrones", "relación", "correlación", "conexión"]):
                # Usar skill de reconocimiento de patrones
                try:
                    result = await self.execute_skill("pattern_recognition", 
                                                   input_text=input_text, 
                                                   biometric_data=biometric_data,
                                                   user_profile=user_profile, 
                                                   context=context)
                    
                    # Generar respuesta
                    if isinstance(result, dict) and "response" in result:
                        response_text = result["response"]
                    else:
                        # Convertir resultado estructurado a texto
                        response_text = "Reconocimiento de patrones biométricos:\n\n"
                        if isinstance(result, dict):
                            for key, value in result.items():
                                if key != "response":
                                    response_text += f"**{key.replace('_', ' ').title()}**: {value}\n"
                        else:
                            response_text = str(result)
                    
                    # Almacenar resultado en el estado
                    pattern_analyses = self._state.get("pattern_analyses", {})
                    analysis_id = str(uuid.uuid4())
                    pattern_analyses[analysis_id] = result
                    self.update_state("pattern_analyses", pattern_analyses)
                    response_type = "pattern_analysis"
                    
                except Exception as e:
                    logger.error(f"Error al ejecutar skill pattern_recognition: {e}")
                    response_text = "Lo siento, ha ocurrido un error al reconocer patrones en tus datos biométricos."
                    result = {"error": str(e)}
                    analysis_id = None
                
            else:
                # Usar skill de análisis biométrico general
                try:
                    result = await self.execute_skill("biometric_analysis", 
                                                   input_text=input_text, 
                                                   biometric_data=biometric_data,
                                                   user_profile=user_profile, 
                                                   context=context)
                    
                    # Generar respuesta
                    if isinstance(result, dict) and "response" in result:
                        response_text = result["response"]
                    else:
                        # Convertir resultado estructurado a texto
                        response_text = "Análisis de datos biométricos:\n\n"
                        if isinstance(result, dict):
                            for key, value in result.items():
                                if key != "response":
                                    response_text += f"**{key.replace('_', ' ').title()}**: {value}\n"
                        else:
                            response_text = str(result)
                    
                    # Almacenar resultado en el estado
                    biometric_analyses = self._state.get("biometric_analyses", {})
                    analysis_id = str(uuid.uuid4())
                    biometric_analyses[analysis_id] = result
                    self.update_state("biometric_analyses", biometric_analyses)
                    response_type = "biometric_analysis"
                    
                except Exception as e:
                    logger.error(f"Error al ejecutar skill biometric_analysis: {e}")
                    response_text = "Lo siento, ha ocurrido un error al analizar tus datos biométricos."
                    result = {"error": str(e)}
                    analysis_id = None
            
            # Actualizar el contexto con la interacción
            context["history"] = context.get("history", []) + [{
                "user": input_text,
                "bot": response_text,
                "timestamp": time.time(),
                "analysis_type": response_type
            }]
            await self._update_context(context, user_id, session_id)
            
            # Devolver respuesta estandarizada según el protocolo A2A
            return {
                "agent_id": "biometrics_insight_engine",
                "version": "1.2.0",
                "response": {
                    "text": response_text,
                    "type": response_type,
                    "analysis_id": analysis_id,
                    "metadata": {
                        "generated_at": time.time(),
                        "model": "gemini-2.0-flash",
                        "prompt_tokens": len(input_text) // 4,  # Estimación aproximada
                        "completion_tokens": len(response_text) // 4  # Estimación aproximada
                    }
                },
                "user_id": user_id,
                "session_id": session_id,
                "timestamp": time.time(),
                "conversation_id": session_id
            }
            
        except Exception as e:
            logger.error(f"Error al procesar solicitud: {e}")
            # Devolver respuesta de error estandarizada según el protocolo A2A
            return {
                "agent_id": "biometrics_insight_engine",
                "version": "1.2.0",
                "response": {
                    "text": f"Lo siento, ha ocurrido un error al procesar tu solicitud: {str(e)}",
                    "type": "error",
                    "metadata": {
                        "error": str(e),
                        "error_type": type(e).__name__,
                        "generated_at": time.time()
                    }
                },
                "user_id": user_id,
                "session_id": session_id,
                "timestamp": time.time(),
                "conversation_id": session_id
            }
    
    async def execute_skill(self, skill_name: str, **kwargs) -> Dict[str, Any]:
        """
        Ejecuta una skill específica del agente.
        
        Args:
            skill_name: Nombre de la skill a ejecutar
            **kwargs: Argumentos para la skill
            
        Returns:
            Dict[str, Any]: Resultado de la ejecución de la skill
        """
        if skill_name == "image_analysis":
            return await self._execute_image_analysis(**kwargs)
        elif skill_name == "multimodal_analysis":
            return await self._execute_multimodal_analysis(**kwargs)
        else:
            # Implementación existente para otras skills
            # Aquí iría el código para ejecutar las skills originales
            return {"response": f"Ejecutando skill {skill_name} con los parámetros proporcionados"}
    
    async def _execute_image_analysis(self, input_text: str, image_data: Any, **kwargs) -> Dict[str, Any]:
        """
        Ejecuta el análisis de imágenes biométricas.
        
        Args:
            input_text: Texto de entrada del usuario
            image_data: Datos de la imagen a analizar
            **kwargs: Argumentos adicionales
            
        Returns:
            Dict[str, Any]: Resultado del análisis de la imagen
        """
        try:
            # Utilizar el procesador de visión para analizar la imagen
            with self.tracer.start_as_current_span("biometrics_image_analysis"):
                # Construir prompt específico para el análisis de imágenes biométricas
                prompt = f"""
                Eres un experto en análisis de datos biométricos y médicos. Analiza esta imagen con detalle
                y proporciona información relevante sobre los datos biométricos que muestra.
                
                Consulta del usuario: "{input_text}"
                
                Si la imagen muestra resultados de pruebas médicas o análisis de sangre:
                1. Identifica los biomarcadores y sus valores
                2. Indica si están dentro de rangos normales
                3. Explica qué significan estos valores para la salud
                4. Proporciona recomendaciones basadas en estos valores
                
                Si la imagen muestra composición corporal:
                1. Identifica los porcentajes de grasa corporal, masa muscular, etc.
                2. Evalúa estos valores en el contexto de salud general
                3. Sugiere áreas de mejora si es apropiado
                
                Si la imagen muestra datos de dispositivos wearables:
                1. Identifica las métricas mostradas (HRV, sueño, etc.)
                2. Interpreta los valores y patrones
                3. Relaciona estos datos con el bienestar general
                
                Proporciona un análisis detallado, preciso y útil.
                """
                
                # Analizar la imagen utilizando el cliente de visión
                vision_result = await self.vision_client.analyze_image(
                    image_data=image_data,
                    prompt=prompt,
                    temperature=0.2
                )
                
                # Extraer texto si es necesario (para resultados de pruebas, etc.)
                text_result = await self.vision_client.extract_text(image_data)
                
                # Procesar los resultados
                analysis_text = vision_result.get("text", "")
                extracted_text = text_result.get("text", "")
                
                # Generar insights basados en el análisis
                insights_prompt = f"""
                Basándote en el siguiente análisis de una imagen biométrica, genera 3-5 insights clave
                sobre la salud y el bienestar del usuario.
                
                Análisis de la imagen:
                {analysis_text}
                
                Texto extraído de la imagen:
                {extracted_text}
                
                Proporciona insights específicos, accionables y basados en evidencia científica.
                """
                
                insights_response = await self.gemini_client.generate_response(insights_prompt, temperature=0.3)
                
                # Generar recomendaciones personalizadas
                recommendations_prompt = f"""
                Basándote en el siguiente análisis de una imagen biométrica, genera 3-5 recomendaciones
                personalizadas para mejorar la salud y el bienestar del usuario.
                
                Análisis de la imagen:
                {analysis_text}
                
                Texto extraído de la imagen:
                {extracted_text}
                
                Proporciona recomendaciones específicas, accionables y basadas en evidencia científica.
                """
                
                recommendations_response = await self.gemini_client.generate_response(recommendations_prompt, temperature=0.3)
                
                # Construir respuesta final
                result = {
                    "response": f"{analysis_text}\n\n**Insights Clave:**\n{insights_response}\n\n**Recomendaciones Personalizadas:**\n{recommendations_response}",
                    "analysis": analysis_text,
                    "extracted_text": extracted_text,
                    "insights": insights_response,
                    "recommendations": recommendations_response,
                    "image_type": self._determine_image_type(analysis_text)
                }
                
                return result
                
        except Exception as e:
            logger.error(f"Error en análisis de imagen: {e}", exc_info=True)
            return {
                "response": f"Lo siento, ha ocurrido un error al analizar la imagen: {str(e)}",
                "error": str(e)
            }
    
    async def _execute_multimodal_analysis(self, input_text: str, image_data: Any, **kwargs) -> Dict[str, Any]:
        """
        Ejecuta el análisis multimodal de datos biométricos.
        
        Args:
            input_text: Texto de entrada del usuario
            image_data: Datos de la imagen a analizar
            **kwargs: Argumentos adicionales
            
        Returns:
            Dict[str, Any]: Resultado del análisis multimodal
        """
        try:
            # Utilizar el adaptador multimodal para procesar la entrada
            with self.tracer.start_as_current_span("biometrics_multimodal_analysis"):
                # Construir prompt específico para el análisis multimodal
                prompt = f"""
                Eres un experto en análisis de datos biométricos y médicos. Analiza esta imagen junto con la consulta
                del usuario y proporciona un análisis detallado que integre ambas fuentes de información.
                
                Consulta del usuario: "{input_text}"
                
                Proporciona:
                1. Un análisis detallado de los datos biométricos mostrados en la imagen
                2. Interpretación de estos datos en el contexto de la consulta del usuario
                3. Insights sobre patrones o tendencias relevantes
                4. Recomendaciones personalizadas basadas en el análisis
                
                Asegúrate de que tu respuesta sea detallada, precisa y útil para el usuario.
                """
                
                # Procesar la entrada multimodal
                multimodal_result = await self.multimodal_adapter.process_multimodal(
                    prompt=prompt,
                    image_data=image_data,
                    temperature=0.2,
                    max_output_tokens=1024
                )
                
                # Procesar los resultados
                analysis_text = multimodal_result.get("text", "")
                
                # Generar insights basados en el análisis
                insights_prompt = f"""
                Basándote en el siguiente análisis multimodal de datos biométricos, genera 3-5 insights clave
                sobre la salud y el bienestar del usuario.
                
                Análisis multimodal:
                {analysis_text}
                
                Proporciona insights específicos, accionables y basados en evidencia científica.
                """
                
                insights_response = await self.gemini_client.generate_response(insights_prompt, temperature=0.3)
                
                # Generar recomendaciones personalizadas
                recommendations_prompt = f"""
                Basándote en el siguiente análisis multimodal de datos biométricos, genera 3-5 recomendaciones
                personalizadas para mejorar la salud y el bienestar del usuario.
                
                Análisis multimodal:
                {analysis_text}
                
                Proporciona recomendaciones específicas, accionables y basadas en evidencia científica.
                """
                
                recommendations_response = await self.gemini_client.generate_response(recommendations_prompt, temperature=0.3)
                
                # Construir respuesta final
                result = {
                    "response": f"{analysis_text}\n\n**Insights Clave:**\n{insights_response}\n\n**Recomendaciones Personalizadas:**\n{recommendations_response}",
                    "analysis": analysis_text,
                    "insights": insights_response,
                    "recommendations": recommendations_response
                }
                
                return result
                
        except Exception as e:
            logger.error(f"Error en análisis multimodal: {e}", exc_info=True)
            return {
                "response": f"Lo siento, ha ocurrido un error al realizar el análisis multimodal: {str(e)}",
                "error": str(e)
            }
    
    def _determine_image_type(self, analysis_text: str) -> str:
        """
        Determina el tipo de imagen biométrica basado en el análisis.
        
        Args:
            analysis_text: Texto del análisis de la imagen
            
        Returns:
            str: Tipo de imagen (body_composition, blood_test, wearable_data, etc.)
        """
        analysis_lower = analysis_text.lower()
        
        if any(term in analysis_lower for term in ["grasa corporal", "masa muscular", "composición corporal", "dexa", "inbody"]):
            return "body_composition"
        elif any(term in analysis_lower for term in ["sangre", "hemograma", "colesterol", "glucosa", "triglicéridos"]):
            return "blood_test"
        elif any(term in analysis_lower for term in ["hrv", "variabilidad", "sueño", "oura", "whoop", "garmin", "fitbit"]):
            return "wearable_data"
        elif any(term in analysis_lower for term in ["hormonal", "hormonas", "testosterona", "cortisol", "tiroides"]):
            return "hormone_test"
        else:
            return "other_biometric_data"
    
    def _get_sample_biometric_data(self) -> Dict[str, Any]:
        """
        Proporciona datos biométricos de muestra para pruebas.
        
        Returns:
            Dict[str, Any]: Datos biométricos de muestra
        """
        # Implementación existente
        return {
            "hrv": {
                "daily": [65, 68, 72, 70, 67, 69, 71],
                "weekly_avg": 69,
                "trend": "stable"
            },
            "sleep": {
                "duration": [7.2, 6.8, 7.5, 7.0, 6.5, 8.0, 7.2],
                "quality": [85, 80, 88, 82, 75, 90, 84],
                "deep_sleep": [1.2, 1.0, 1.4, 1.1, 0.9, 1.5, 1.2]
            },
            "body_composition": {
                "weight": 75.5,
                "body_fat": 18.2,
                "muscle_mass": 58.4,
                "bone_density": 1.08
            }
        }
